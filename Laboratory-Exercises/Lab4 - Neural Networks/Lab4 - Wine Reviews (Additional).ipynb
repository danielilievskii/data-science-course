{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "c2c274f5ee5144019ba47a3b48385929": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fe04762fb97040808cd54bd036d4a553",
       "IPY_MODEL_f062c13538c6492ab395c5545c36da9b",
       "IPY_MODEL_1ea55b71cc89440cb3f1a4f09d18512a"
      ],
      "layout": "IPY_MODEL_160d148481874635a218c22bc3222d4f"
     }
    },
    "fe04762fb97040808cd54bd036d4a553": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4ef2e3004f2b40edb0c55d7ef0c8212f",
      "placeholder": "​",
      "style": "IPY_MODEL_7d50007468c14547b66bca597464f3c4",
      "value": "Generating train split: "
     }
    },
    "f062c13538c6492ab395c5545c36da9b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8029186ad5346b5b4f8668669fb8edc",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_b580b838fa104c2e80e897d04c754479",
      "value": 1
     }
    },
    "1ea55b71cc89440cb3f1a4f09d18512a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ec020e0c7c0419c837ca582bcc4c3ea",
      "placeholder": "​",
      "style": "IPY_MODEL_3a7aaf6523fb4def9f648870586b76bb",
      "value": " 10000/0 [00:00&lt;00:00, 47398.62 examples/s]"
     }
    },
    "160d148481874635a218c22bc3222d4f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4ef2e3004f2b40edb0c55d7ef0c8212f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7d50007468c14547b66bca597464f3c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b8029186ad5346b5b4f8668669fb8edc": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": "20px"
     }
    },
    "b580b838fa104c2e80e897d04c754479": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "3ec020e0c7c0419c837ca582bcc4c3ea": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3a7aaf6523fb4def9f648870586b76bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e5766f033ae647a083b7118e9390bd8d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_77c005cac3aa4594b2e20c926935c5f0",
       "IPY_MODEL_257b88ba7ae6457cbd33a7e0fe08453c",
       "IPY_MODEL_72e7f7e190f342d7bfe094663cdb7dbc"
      ],
      "layout": "IPY_MODEL_d448f9efad5e4231b5d240fad51b429e"
     }
    },
    "77c005cac3aa4594b2e20c926935c5f0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b663598c8ec84151b0a0bba6b1caae25",
      "placeholder": "​",
      "style": "IPY_MODEL_c4b7a4efe68b43099604da6943ac58a0",
      "value": "Map: 100%"
     }
    },
    "257b88ba7ae6457cbd33a7e0fe08453c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_32feb258ca364422ab9bf9d658e5d3c6",
      "max": 8000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_addc7a3296ca4324b8e4e8ef07b9d535",
      "value": 8000
     }
    },
    "72e7f7e190f342d7bfe094663cdb7dbc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c0cf91ab0fe944cca8b4cf2b333beec5",
      "placeholder": "​",
      "style": "IPY_MODEL_c0df411557f041278ff204332000bd27",
      "value": " 8000/8000 [00:02&lt;00:00, 2546.61 examples/s]"
     }
    },
    "d448f9efad5e4231b5d240fad51b429e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b663598c8ec84151b0a0bba6b1caae25": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4b7a4efe68b43099604da6943ac58a0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "32feb258ca364422ab9bf9d658e5d3c6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "addc7a3296ca4324b8e4e8ef07b9d535": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c0cf91ab0fe944cca8b4cf2b333beec5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c0df411557f041278ff204332000bd27": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "80353904d74c47bd8fd28c46fb7f59e2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ef5f5538f0814bc4bd882c6e7221dc69",
       "IPY_MODEL_57dc2e25146d4b06a14702b621134751",
       "IPY_MODEL_7a135529baab44f6bde402651ddaccda"
      ],
      "layout": "IPY_MODEL_c9dfb40bef23408f94aa4d3680f41b09"
     }
    },
    "ef5f5538f0814bc4bd882c6e7221dc69": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_be78e84338b94215bfe33f8fcc3ab068",
      "placeholder": "​",
      "style": "IPY_MODEL_eed5c466b79649769782152fd4e51ea0",
      "value": "Map: 100%"
     }
    },
    "57dc2e25146d4b06a14702b621134751": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b0c7d986a0354a67b524d384be04ffbb",
      "max": 2000,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_5ebadd1050b04875adb4f9f2f82ef24c",
      "value": 2000
     }
    },
    "7a135529baab44f6bde402651ddaccda": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "model_module_version": "1.5.0",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_48f0d5dddc5e4623a4442b5f133b2726",
      "placeholder": "​",
      "style": "IPY_MODEL_8eddf68854784a37b1bda93d21ae6198",
      "value": " 2000/2000 [00:00&lt;00:00, 2181.95 examples/s]"
     }
    },
    "c9dfb40bef23408f94aa4d3680f41b09": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be78e84338b94215bfe33f8fcc3ab068": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "eed5c466b79649769782152fd4e51ea0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b0c7d986a0354a67b524d384be04ffbb": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5ebadd1050b04875adb4f9f2f82ef24c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "48f0d5dddc5e4623a4442b5f133b2726": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "model_module_version": "1.2.0",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8eddf68854784a37b1bda93d21ae6198": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "model_module_version": "1.5.0",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Requirements"
   ],
   "metadata": {
    "id": "rODb9vHvIEbp"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T11:17:24.847189Z",
     "start_time": "2024-12-20T11:17:20.757214Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install transformers[torch]",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (4.47.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from transformers[torch]) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from transformers[torch]) (0.27.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from transformers[torch]) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from transformers[torch]) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from transformers[torch]) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from transformers[torch]) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from transformers[torch]) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from transformers[torch]) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from transformers[torch]) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from transformers[torch]) (4.67.1)\n",
      "Requirement already satisfied: torch in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from transformers[torch]) (2.5.1)\n",
      "Collecting accelerate>=0.26.0 (from transformers[torch])\n",
      "  Downloading accelerate-1.2.1-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from accelerate>=0.26.0->transformers[torch]) (5.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from huggingface-hub<1.0,>=0.24.0->transformers[torch]) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from torch->transformers[torch]) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from torch->transformers[torch]) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from torch->transformers[torch]) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from torch->transformers[torch]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from sympy==1.13.1->torch->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from tqdm>=4.27->transformers[torch]) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from requests->transformers[torch]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from requests->transformers[torch]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from requests->transformers[torch]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from requests->transformers[torch]) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\dilie\\miniconda3\\envs\\data-science-course\\lib\\site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\n",
      "Downloading accelerate-1.2.1-py3-none-any.whl (336 kB)\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.2.1\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "source": [
    "# Add as many imports as you need.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
    "import torch"
   ],
   "metadata": {
    "id": "U4KmHBd2cdx9",
    "ExecuteTime": {
     "end_time": "2024-12-20T11:13:59.106855Z",
     "start_time": "2024-12-20T11:13:55.001137Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\dilie\\miniconda3\\envs\\data-science-course\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset, Dataset"
   ],
   "metadata": {
    "id": "ZDtmeJTYUUxb",
    "ExecuteTime": {
     "end_time": "2024-12-20T11:14:00.392520Z",
     "start_time": "2024-12-20T11:14:00.386553Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Laboratory Exercise - Run Mode (8 points)"
   ],
   "metadata": {
    "id": "KNMMoUiUIW3L"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Introduction\n",
    "This laboratory assignment's primary objective is to fine-tune a pre-trained language model for binary classification on a dataset consisting of wine reviews. The dataset contains two attributes: **description** and **points**. The description is a brief text describing the wine and the points represent a quality metric ranging from 1 to 100. If some wine has at least 90 points it is considered **exceptional**. Your task involves predicting if some wine is **exceptional** based on its review."
   ],
   "metadata": {
    "id": "_rAh_91OIjeS"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## The Wine Reviews Dataset"
   ],
   "metadata": {
    "id": "zBYI-EypaWom"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Load the dataset using the `datasets` library."
   ],
   "metadata": {
    "id": "DCm1qm1mZwMr"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "wine_reviews = load_dataset('csv', data_files='./data/wine-reviews.csv')"
   ],
   "metadata": {
    "id": "KMOn4fgcZn8s",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "c2c274f5ee5144019ba47a3b48385929",
      "fe04762fb97040808cd54bd036d4a553",
      "f062c13538c6492ab395c5545c36da9b",
      "1ea55b71cc89440cb3f1a4f09d18512a",
      "160d148481874635a218c22bc3222d4f",
      "4ef2e3004f2b40edb0c55d7ef0c8212f",
      "7d50007468c14547b66bca597464f3c4",
      "b8029186ad5346b5b4f8668669fb8edc",
      "b580b838fa104c2e80e897d04c754479",
      "3ec020e0c7c0419c837ca582bcc4c3ea",
      "3a7aaf6523fb4def9f648870586b76bb"
     ]
    },
    "outputId": "3b46a9eb-a19a-4ad7-d549-e67172239f22",
    "ExecuteTime": {
     "end_time": "2024-12-20T11:14:03.849079Z",
     "start_time": "2024-12-20T11:14:03.134614Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "wine_reviews"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9UlENe1RVy_1",
    "outputId": "d5264c70-ffbc-4ec0-81d9-1b5c56780b62",
    "ExecuteTime": {
     "end_time": "2024-12-20T11:14:03.865083Z",
     "start_time": "2024-12-20T11:14:03.849079Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['description', 'points'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "df = wine_reviews[\"train\"].to_pandas()\n",
    "df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "AGO_4n7rV79D",
    "outputId": "45dcfb5c-375d-4c04-f8cc-113dd6102c62",
    "ExecuteTime": {
     "end_time": "2024-12-20T11:14:04.124845Z",
     "start_time": "2024-12-20T11:14:04.099967Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            description  points\n",
       "0     Translucent in color, silky in the mouth, this...      85\n",
       "1     On the palate, this wine is rich and complex, ...      92\n",
       "2     The producer blends 57% Chardonnay from the Ma...      92\n",
       "3     Pure Baga in all its glory, packed with dry an...      93\n",
       "4     Think of Subsídio as a contribution rather tha...      89\n",
       "...                                                 ...     ...\n",
       "9995  From the folks at Merryvale, this is a blend o...      92\n",
       "9996  An easy, versatile food wine or cocktail sippe...      84\n",
       "9997  Black-fruit aromas blend nicely into chocolate...      93\n",
       "9998  This combines 61% Cabernet Sauvignon, 14% Syra...      90\n",
       "9999  This is Ferreira's top vineyard that also prod...      94\n",
       "\n",
       "[10000 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Translucent in color, silky in the mouth, this...</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On the palate, this wine is rich and complex, ...</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The producer blends 57% Chardonnay from the Ma...</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pure Baga in all its glory, packed with dry an...</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Think of Subsídio as a contribution rather tha...</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>From the folks at Merryvale, this is a blend o...</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>An easy, versatile food wine or cocktail sippe...</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Black-fruit aromas blend nicely into chocolate...</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>This combines 61% Cabernet Sauvignon, 14% Syra...</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>This is Ferreira's top vineyard that also prod...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Target Extraction\n",
    "Extract the target **exceptional** for each wine review. If some wine has at least 90 points it is considered **exceptional**."
   ],
   "metadata": {
    "id": "hZceBEFuiGpI"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "df['exceptional'] = (df['points'] >= 90).astype(int)\n",
    "df"
   ],
   "metadata": {
    "id": "Duz8bzcRKSC7",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "outputId": "31f6116d-6206-4381-ffe3-9a6acd7097e9",
    "ExecuteTime": {
     "end_time": "2024-12-20T11:14:08.611104Z",
     "start_time": "2024-12-20T11:14:08.591609Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            description  points  exceptional\n",
       "0     Translucent in color, silky in the mouth, this...      85            0\n",
       "1     On the palate, this wine is rich and complex, ...      92            1\n",
       "2     The producer blends 57% Chardonnay from the Ma...      92            1\n",
       "3     Pure Baga in all its glory, packed with dry an...      93            1\n",
       "4     Think of Subsídio as a contribution rather tha...      89            0\n",
       "...                                                 ...     ...          ...\n",
       "9995  From the folks at Merryvale, this is a blend o...      92            1\n",
       "9996  An easy, versatile food wine or cocktail sippe...      84            0\n",
       "9997  Black-fruit aromas blend nicely into chocolate...      93            1\n",
       "9998  This combines 61% Cabernet Sauvignon, 14% Syra...      90            1\n",
       "9999  This is Ferreira's top vineyard that also prod...      94            1\n",
       "\n",
       "[10000 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>points</th>\n",
       "      <th>exceptional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Translucent in color, silky in the mouth, this...</td>\n",
       "      <td>85</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>On the palate, this wine is rich and complex, ...</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The producer blends 57% Chardonnay from the Ma...</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pure Baga in all its glory, packed with dry an...</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Think of Subsídio as a contribution rather tha...</td>\n",
       "      <td>89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>From the folks at Merryvale, this is a blend o...</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>An easy, versatile food wine or cocktail sippe...</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Black-fruit aromas blend nicely into chocolate...</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>This combines 61% Cabernet Sauvignon, 14% Syra...</td>\n",
       "      <td>90</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>This is Ferreira's top vineyard that also prod...</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "wine_reviews[\"train\"] = wine_reviews[\"train\"].add_column(\"label\", df['exceptional'])"
   ],
   "metadata": {
    "id": "u2Db9SCMfOiq",
    "ExecuteTime": {
     "end_time": "2024-12-20T11:14:10.171335Z",
     "start_time": "2024-12-20T11:14:10.156288Z"
    }
   },
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "wine_reviews"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E2RGh0jQfP68",
    "outputId": "0029c345-dc30-47ff-9ada-ca4e4cd7aee9",
    "ExecuteTime": {
     "end_time": "2024-12-20T11:14:10.384075Z",
     "start_time": "2024-12-20T11:14:10.378503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['description', 'points', 'label'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset Splitting\n",
    "Partition the dataset into training and testing sets with an 80:20 ratio.\n"
   ],
   "metadata": {
    "id": "tls69_PrbJKW"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T11:14:12.480070Z",
     "start_time": "2024-12-20T11:14:12.410965Z"
    }
   },
   "cell_type": "code",
   "source": "wine_reviews = wine_reviews['train'].train_test_split(test_size=0.2)",
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": "wine_reviews",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U8ASMasgXKRa",
    "outputId": "c6ee2e7a-9db3-409e-9fd6-e432b761b5df",
    "ExecuteTime": {
     "end_time": "2024-12-20T11:14:12.588025Z",
     "start_time": "2024-12-20T11:14:12.581480Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['description', 'points', 'label'],\n",
       "        num_rows: 8000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['description', 'points', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenization\n",
    "Tokenize the texts using the `AutoTokenizer` class."
   ],
   "metadata": {
    "id": "NLnr8v_dWO1i"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"description\"],\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "train_dataset = wine_reviews['train'].map(tokenize_function, batched=True)\n",
    "test_dataset = wine_reviews['test'].map(tokenize_function, batched=True)"
   ],
   "metadata": {
    "id": "esakOh8iWYEN",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81,
     "referenced_widgets": [
      "e5766f033ae647a083b7118e9390bd8d",
      "77c005cac3aa4594b2e20c926935c5f0",
      "257b88ba7ae6457cbd33a7e0fe08453c",
      "72e7f7e190f342d7bfe094663cdb7dbc",
      "d448f9efad5e4231b5d240fad51b429e",
      "b663598c8ec84151b0a0bba6b1caae25",
      "c4b7a4efe68b43099604da6943ac58a0",
      "32feb258ca364422ab9bf9d658e5d3c6",
      "addc7a3296ca4324b8e4e8ef07b9d535",
      "c0cf91ab0fe944cca8b4cf2b333beec5",
      "c0df411557f041278ff204332000bd27",
      "80353904d74c47bd8fd28c46fb7f59e2",
      "ef5f5538f0814bc4bd882c6e7221dc69",
      "57dc2e25146d4b06a14702b621134751",
      "7a135529baab44f6bde402651ddaccda",
      "c9dfb40bef23408f94aa4d3680f41b09",
      "be78e84338b94215bfe33f8fcc3ab068",
      "eed5c466b79649769782152fd4e51ea0",
      "b0c7d986a0354a67b524d384be04ffbb",
      "5ebadd1050b04875adb4f9f2f82ef24c",
      "48f0d5dddc5e4623a4442b5f133b2726",
      "8eddf68854784a37b1bda93d21ae6198"
     ]
    },
    "outputId": "04999ad4-6574-4666-8d67-ed3601d23175",
    "ExecuteTime": {
     "end_time": "2024-12-20T11:14:16.494830Z",
     "start_time": "2024-12-20T11:14:13.711009Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d00ad5c62d2c41b698e3b2e2ce5875fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b5bdaf0c3dcc46d190f7bcafbe56a2dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "test_dataset"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wd5-Awxfc1jA",
    "outputId": "75081284-da20-440a-9df9-1573b0668833",
    "ExecuteTime": {
     "end_time": "2024-12-20T11:14:16.509394Z",
     "start_time": "2024-12-20T11:14:16.502426Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['description', 'points', 'label', 'input_ids', 'attention_mask'],\n",
       "    num_rows: 2000\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine-tuning a Pre-trained Language Model for Classification\n",
    "Fine-tune a pre-trained language model for classification on the given dataset."
   ],
   "metadata": {
    "id": "VIkAR1Hibiwr"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the model using the `AutoModelForSequenceClassification` class."
   ],
   "metadata": {
    "id": "qWn1pafKbnxH"
   }
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-20T11:14:16.782167Z",
     "start_time": "2024-12-20T11:14:16.763004Z"
    }
   },
   "cell_type": "code",
   "source": "import torch",
   "outputs": [],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "# import torch\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=2)"
   ],
   "metadata": {
    "id": "IXFIrQthbnkb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ef119479-27fa-4c93-9ab2-165fa7b0ac62",
    "ExecuteTime": {
     "end_time": "2024-12-20T11:15:54.467441Z",
     "start_time": "2024-12-20T11:14:24.661883Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23fd449ec663468799c829367ad3f485"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dilie\\miniconda3\\envs\\data-science-course\\Lib\\site-packages\\huggingface_hub\\file_download.py:140: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\dilie\\.cache\\huggingface\\hub\\models--bert-base-cased. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0872c04b39ec4888b334d19ba6f4e673"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the traning parameters using the `TrainingArguments` class."
   ],
   "metadata": {
    "id": "IuQCSxZbYJOq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    report_to=\"none\",\n",
    ")"
   ],
   "metadata": {
    "id": "p3sVs-L1YJHu",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "01f84807-a628-48ca-9670-526c06ba2463",
    "ExecuteTime": {
     "end_time": "2024-12-20T11:18:25.581428Z",
     "start_time": "2024-12-20T11:18:25.449652Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>={ACCELERATE_MIN_VERSION}'`",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[24], line 4\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Write your code here. Add as many boxes as you need.\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtransformers\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TrainingArguments, Trainer\n\u001B[1;32m----> 4\u001B[0m training_args \u001B[38;5;241m=\u001B[39m TrainingArguments(\n\u001B[0;32m      5\u001B[0m     output_dir\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m./results\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      6\u001B[0m     eval_strategy\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mepoch\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      7\u001B[0m     per_device_train_batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m,\n\u001B[0;32m      8\u001B[0m     per_device_eval_batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m16\u001B[39m,\n\u001B[0;32m      9\u001B[0m     metric_for_best_model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mf1\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     10\u001B[0m     report_to\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnone\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     11\u001B[0m )\n",
      "File \u001B[1;32m<string>:134\u001B[0m, in \u001B[0;36m__init__\u001B[1;34m(self, output_dir, overwrite_output_dir, do_train, do_eval, do_predict, eval_strategy, prediction_loss_only, per_device_train_batch_size, per_device_eval_batch_size, per_gpu_train_batch_size, per_gpu_eval_batch_size, gradient_accumulation_steps, eval_accumulation_steps, eval_delay, torch_empty_cache_steps, learning_rate, weight_decay, adam_beta1, adam_beta2, adam_epsilon, max_grad_norm, num_train_epochs, max_steps, lr_scheduler_type, lr_scheduler_kwargs, warmup_ratio, warmup_steps, log_level, log_level_replica, log_on_each_node, logging_dir, logging_strategy, logging_first_step, logging_steps, logging_nan_inf_filter, save_strategy, save_steps, save_total_limit, save_safetensors, save_on_each_node, save_only_model, restore_callback_states_from_checkpoint, no_cuda, use_cpu, use_mps_device, seed, data_seed, jit_mode_eval, use_ipex, bf16, fp16, fp16_opt_level, half_precision_backend, bf16_full_eval, fp16_full_eval, tf32, local_rank, ddp_backend, tpu_num_cores, tpu_metrics_debug, debug, dataloader_drop_last, eval_steps, dataloader_num_workers, dataloader_prefetch_factor, past_index, run_name, disable_tqdm, remove_unused_columns, label_names, load_best_model_at_end, metric_for_best_model, greater_is_better, ignore_data_skip, fsdp, fsdp_min_num_params, fsdp_config, fsdp_transformer_layer_cls_to_wrap, accelerator_config, deepspeed, label_smoothing_factor, optim, optim_args, adafactor, group_by_length, length_column_name, report_to, ddp_find_unused_parameters, ddp_bucket_cap_mb, ddp_broadcast_buffers, dataloader_pin_memory, dataloader_persistent_workers, skip_memory_metrics, use_legacy_prediction_loop, push_to_hub, resume_from_checkpoint, hub_model_id, hub_strategy, hub_token, hub_private_repo, hub_always_push, gradient_checkpointing, gradient_checkpointing_kwargs, include_inputs_for_metrics, include_for_metrics, eval_do_concat_batches, fp16_backend, evaluation_strategy, push_to_hub_model_id, push_to_hub_organization, push_to_hub_token, mp_parameters, auto_find_batch_size, full_determinism, torchdynamo, ray_scope, ddp_timeout, torch_compile, torch_compile_backend, torch_compile_mode, dispatch_batches, split_batches, include_tokens_per_second, include_num_input_tokens_seen, neftune_noise_alpha, optim_target_modules, batch_eval_metrics, eval_on_start, use_liger_kernel, eval_use_gather_object, average_tokens_across_devices)\u001B[0m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\data-science-course\\Lib\\site-packages\\transformers\\training_args.py:1780\u001B[0m, in \u001B[0;36mTrainingArguments.__post_init__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   1778\u001B[0m \u001B[38;5;66;03m# Initialize device before we proceed\u001B[39;00m\n\u001B[0;32m   1779\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mframework \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpt\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m is_torch_available():\n\u001B[1;32m-> 1780\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice\n\u001B[0;32m   1782\u001B[0m \u001B[38;5;66;03m# Disable average tokens when using single device\u001B[39;00m\n\u001B[0;32m   1783\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39maverage_tokens_across_devices:\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\data-science-course\\Lib\\site-packages\\transformers\\training_args.py:2306\u001B[0m, in \u001B[0;36mTrainingArguments.device\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   2302\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2303\u001B[0m \u001B[38;5;124;03mThe device used by this process.\u001B[39;00m\n\u001B[0;32m   2304\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m   2305\u001B[0m requires_backends(\u001B[38;5;28mself\u001B[39m, [\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtorch\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n\u001B[1;32m-> 2306\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_setup_devices\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\data-science-course\\Lib\\site-packages\\transformers\\utils\\generic.py:60\u001B[0m, in \u001B[0;36mcached_property.__get__\u001B[1;34m(self, obj, objtype)\u001B[0m\n\u001B[0;32m     58\u001B[0m cached \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(obj, attr, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m     59\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cached \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m---> 60\u001B[0m     cached \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfget(obj)\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;28msetattr\u001B[39m(obj, attr, cached)\n\u001B[0;32m     62\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m cached\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\data-science-course\\Lib\\site-packages\\transformers\\training_args.py:2179\u001B[0m, in \u001B[0;36mTrainingArguments._setup_devices\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m   2177\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_sagemaker_mp_enabled():\n\u001B[0;32m   2178\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_accelerate_available():\n\u001B[1;32m-> 2179\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m(\n\u001B[0;32m   2180\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUsing the `Trainer` with `PyTorch` requires `accelerate>=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mACCELERATE_MIN_VERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m`: \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2181\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPlease run `pip install transformers[torch]` or `pip install \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124maccelerate>=\u001B[39m\u001B[38;5;132;01m{ACCELERATE_MIN_VERSION}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2182\u001B[0m         )\n\u001B[0;32m   2183\u001B[0m \u001B[38;5;66;03m# We delay the init of `PartialState` to the end for clarity\u001B[39;00m\n\u001B[0;32m   2184\u001B[0m accelerator_state_kwargs \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124menabled\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muse_configured_state\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;28;01mFalse\u001B[39;00m}\n",
      "\u001B[1;31mImportError\u001B[0m: Using the `Trainer` with `PyTorch` requires `accelerate>=0.26.0`: Please run `pip install transformers[torch]` or `pip install 'accelerate>={ACCELERATE_MIN_VERSION}'`"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the training using the `Trainer` class."
   ],
   "metadata": {
    "id": "pVvRS4L1YKHp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ],
   "metadata": {
    "id": "O7cyG3PhYJ_M",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "03c70ce0-af76-40c0-a1cf-df558ad06ff2"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<ipython-input-78-42ab505b2424>:2: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fine-tune (train) the pre-trained lanugage model."
   ],
   "metadata": {
    "id": "qFZr21HxYkko"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "trainer.train()"
   ],
   "metadata": {
    "id": "U9Dz0P11Ykeh",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 321
    },
    "outputId": "e09504e8-59ec-4d3c-b004-037ec452d316"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-79-11fbdaf29577>\u001B[0m in \u001B[0;36m<cell line: 2>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;31m# Write your code here. Add as many boxes as you need.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mtrainer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001B[0m\n\u001B[1;32m   2162\u001B[0m                 \u001B[0mhf_hub_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0menable_progress_bars\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2163\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2164\u001B[0;31m             return inner_training_loop(\n\u001B[0m\u001B[1;32m   2165\u001B[0m                 \u001B[0margs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2166\u001B[0m                 \u001B[0mresume_from_checkpoint\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mresume_from_checkpoint\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001B[0m in \u001B[0;36m_inner_training_loop\u001B[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001B[0m\n\u001B[1;32m   2470\u001B[0m                 \u001B[0mupdate_step\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2471\u001B[0m                 \u001B[0mnum_batches\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0margs\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgradient_accumulation_steps\u001B[0m \u001B[0;32mif\u001B[0m \u001B[0mupdate_step\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mtotal_updates\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32melse\u001B[0m \u001B[0mremainder\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2472\u001B[0;31m                 \u001B[0mbatch_samples\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_items_in_batch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_batch_samples\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch_iterator\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnum_batches\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2473\u001B[0m                 \u001B[0;32mfor\u001B[0m \u001B[0mi\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0minputs\u001B[0m \u001B[0;32min\u001B[0m \u001B[0menumerate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mbatch_samples\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2474\u001B[0m                     \u001B[0mstep\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001B[0m in \u001B[0;36mget_batch_samples\u001B[0;34m(self, epoch_iterator, num_batches)\u001B[0m\n\u001B[1;32m   5129\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0m_\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mnum_batches\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5130\u001B[0m             \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 5131\u001B[0;31m                 \u001B[0mbatch_samples\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch_iterator\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   5132\u001B[0m             \u001B[0;32mexcept\u001B[0m \u001B[0mStopIteration\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   5133\u001B[0m                 \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/accelerate/data_loader.py\u001B[0m in \u001B[0;36m__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    550\u001B[0m         \u001B[0;31m# We iterate one batch ahead to check when we are at the end\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    551\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 552\u001B[0;31m             \u001B[0mcurrent_batch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mnext\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdataloader_iter\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    553\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mStopIteration\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    554\u001B[0m             \u001B[0;32myield\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    699\u001B[0m                 \u001B[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    700\u001B[0m                 \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# type: ignore[call-arg]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 701\u001B[0;31m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    702\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_num_yielded\u001B[0m \u001B[0;34m+=\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    703\u001B[0m             if (\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001B[0m in \u001B[0;36m_next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    755\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_next_data\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    756\u001B[0m         \u001B[0mindex\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_next_index\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 757\u001B[0;31m         \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_dataset_fetcher\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfetch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mindex\u001B[0m\u001B[0;34m)\u001B[0m  \u001B[0;31m# may raise StopIteration\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    758\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    759\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_utils\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpin_memory\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_pin_memory_device\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001B[0m in \u001B[0;36mfetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     53\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     54\u001B[0m             \u001B[0mdata\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mpossibly_batched_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 55\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcollate_fn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer_utils.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, features)\u001B[0m\n\u001B[1;32m    846\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeatures\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mList\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mdict\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    847\u001B[0m         \u001B[0mfeatures\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_remove_columns\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfeature\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfor\u001B[0m \u001B[0mfeature\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mfeatures\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 848\u001B[0;31m         \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdata_collator\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfeatures\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    849\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    850\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/transformers/data/data_collator.py\u001B[0m in \u001B[0;36m__call__\u001B[0;34m(self, features)\u001B[0m\n\u001B[1;32m    269\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    270\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__call__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfeatures\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mList\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mDict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mDict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mAny\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 271\u001B[0;31m         batch = pad_without_fast_tokenizer_warning(\n\u001B[0m\u001B[1;32m    272\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtokenizer\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    273\u001B[0m             \u001B[0mfeatures\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/transformers/data/data_collator.py\u001B[0m in \u001B[0;36mpad_without_fast_tokenizer_warning\u001B[0;34m(tokenizer, *pad_args, **pad_kwargs)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 66\u001B[0;31m         \u001B[0mpadded\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtokenizer\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpad\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0mpad_args\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mpad_kwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     67\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     68\u001B[0m         \u001B[0;31m# Restore the state of the warning.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001B[0m in \u001B[0;36mpad\u001B[0;34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, padding_side, return_attention_mask, return_tensors, verbose)\u001B[0m\n\u001B[1;32m   3295\u001B[0m         \u001B[0;31m# The model's main input name, usually `input_ids`, has been passed for padding\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3296\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel_input_names\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mencoded_inputs\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 3297\u001B[0;31m             raise ValueError(\n\u001B[0m\u001B[1;32m   3298\u001B[0m                 \u001B[0;34m\"You should supply an encoding or a list of encodings to this method \"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   3299\u001B[0m                 \u001B[0;34mf\"that includes {self.model_input_names[0]}, but you provided {list(encoded_inputs.keys())}\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: You should supply an encoding or a list of encodings to this method that includes input_ids, but you provided []"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Use the trained model to make predictions for the test set."
   ],
   "metadata": {
    "id": "gyXZwAVab8Cp"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Evaluation Results:\", eval_results)"
   ],
   "metadata": {
    "id": "EvMfVum6b_9b"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Assess the performance of the model by using different metrics provided by the `scikit-learn` library."
   ],
   "metadata": {
    "id": "3VxAvDPtcNCh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Write your code here. Add as many boxes as you need.\n",
    "predictions = trainer.predict(test_dataset)\n",
    "predicted_labels = torch.argmax(torch.tensor(predictions.predictions), dim=1)"
   ],
   "metadata": {
    "id": "V4axpktycQhp"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y_true = test_dataset[\"exceptional\"]\n",
    "print(classification_report(y_true, predicted_labels, target_names=[\"Not Exceptional\", \"Exceptional\"]))"
   ],
   "metadata": {
    "id": "iJEDusu_boOn"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Laboratory Exercise - Bonus Task (+ 2 points)"
   ],
   "metadata": {
    "id": "RwnD_qSpIeXG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Implement a simple machine learning pipeline to classify wine reviews as **exceptional** or not. Use TF-IDF vectorization to convert text into numerical features and train a logistic regression. Split the dataset into training and testing sets, fit the pipeline on the training data, and evaluate its performance using metrics such as precision, recall, and F1-score. Analyze the texts to find the most influential words or phrases associated with the **exceptional** wines. Use the coefficients from the logistic regression trained on TF-IDF features to identify the top positive and negative keywords for **exceptional** wines. Present these keywords in a simple table or visualization (e.g., bar chart)."
   ],
   "metadata": {
    "id": "At5xnEDq3A2h"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Write your code here. Add as many boxes as you need."
   ],
   "metadata": {
    "id": "akxvW5SZ3DoV"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
